---
published: false
key: regularization
tags: ai
---
## 过拟合解决方案
1. 减少特征数量
2. 正则化regularization。保留所有特征，减小特征的权重

## 正则化
线性回归正则化$min_\theta \dfrac{1}{2m}  [\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^n \theta_j^2]$  
**关键点：** 没有惩罚$\theta_{0}$  
**参数越小对应的函数越简单，越不容易过拟合**  

注意，这里把**正则化项除了一个2m**。论坛上看到的比较合理的解释是，除2为了便于求导；除m为了在数据集大小不一样时，便于比较。  

还提到，添加正则化项还有助于解决**矩阵不可逆**的问题

正则化一般不会导致无法收敛：
> Regularized logistic regression and regularized linear regression are both convex, and thus gradient descent will still converge to the global minimum.
